[
  {
    "objectID": "starter-analysis-exercise/data/readme.html",
    "href": "starter-analysis-exercise/data/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all data at various stages.\nThis data is being loaded/manipulated/changed/saved with code from the code folders.\nYou should place the raw data in the raw_data folder and not edit it. Ever!\nIdeally, load the raw data into R and do all changes there with code, so everything is automatically reproducible and documented.\nSometimes, you need to edit the files in the format you got. For instance, Excel files are sometimes so poorly formatted that it’s close to impossible to read them into R, or the persons you got the data from used color to code some information, which of course won’t import into R. In those cases, you might have to make modifications in a software other than R. If you need to make edits in whatever format you got the data (e.g. Excel), make a copy and place those copies in a separate folder, AND ONLY EDIT THOSE COPIES. Also, write down somewhere the edits you made.\nAdd as many sub-folders as suitable. If you only have a single processing step, one sub-folder for processed data is enough. If you have multiple stages of cleaning and processing, additional sub-folders might be useful. Adjust based on the complexity of your project.\nI suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data:\nhttp://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata"
  },
  {
    "objectID": "starter-analysis-exercise/results/figures/readme.html",
    "href": "starter-analysis-exercise/results/figures/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all figures.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/results/tables-files/readme.html",
    "href": "starter-analysis-exercise/results/tables-files/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "Folder for all tables (generally stored as Rds files) and other files.\nYou can create further sub-folders if that makes sense."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\nWarning: package 'dplyr' was built under R version 4.3.1\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at /Users/chirst/Desktop/Git/taylorglass-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 3 × 3\n  `Variable Name` `Variable Definition`                 `Allowed Values`      \n  &lt;chr&gt;           &lt;chr&gt;                                 &lt;chr&gt;                 \n1 Height          height in centimeters                 numeric value &gt;0 or NA\n2 Weight          weight in kilograms                   numeric value &gt;0 or NA\n3 Gender          identified gender (male/female/other) M/F/O/NA              \n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 3\n$ Height &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"155\", …\n$ Weight &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"F\", \"M…\n\nsummary(rawdata)\n\n    Height              Weight          Gender         \n Length:14          Min.   :  45.0   Length:14         \n Class :character   1st Qu.:  55.0   Class :character  \n Mode  :character   Median :  70.0   Mode  :character  \n                    Mean   : 602.7                     \n                    3rd Qu.:  90.0                     \n                    Max.   :7000.0                     \n                    NA's   :1                          \n\nhead(rawdata)\n\n# A tibble: 6 × 3\n  Height Weight Gender\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; \n1 180        80 M     \n2 175        70 O     \n3 sixty      60 F     \n4 178        76 F     \n5 192        90 NA    \n6 6          55 F     \n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55\n70\n90\n7000\n▇▁▁▁▁\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\n\n\nhist(d1$Height)\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85\n110\n▇▂▃▃▂\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n1\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\n\n\n\nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda.html",
    "href": "starter-analysis-exercise/code/eda-code/eda.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at /Users/chirst/Desktop/Git/taylorglass-MADA-portfolio\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.1\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.1\n\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          5     \n_______________________          \nColumn type frequency:           \n  character                1     \n  factor                   1     \n  numeric                  3     \n________________________         \nGroup variables            None  \n\n── Variable type: character ────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate min max empty n_unique whitespace\n1 Race                  0             1   1   4     0        4          0\n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts      \n1 Gender                0             1 FALSE          3 M: 4, F: 3, O: 2\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n3 Age                   0             1  42.8 20.2  16  23  45  51   77 ▆▁▇▂▂\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/analysis-code/readme.html",
    "href": "starter-analysis-exercise/code/analysis-code/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory analysis and statistical analysis on the processed/cleaned data. The code produces a few tables and figures, which are saved in the results folder.\nIt’s the same code done 3 times:\n\nFirst, there is an R script that you can run which does all the computations.\nSecond, there is a Quarto file which contains exactly the same code as the R script.\nThird, my current favorite, is a Quarto file with an approach where the code is pulled in from the R script and run.\n\nThe last version has the advantage of having code in one place for easy writing/debugging, and then being able to pull the code into the Quarto file for a nice combination of text/commentary and code.\nEach way of doing this is a reasonable approach, pick whichever one you prefer or makes the most sense for your setup. Whichever approach you choose, add ample documentation/commentary so you and others can easily understand what’s going on and what is done."
  },
  {
    "objectID": "starter-analysis-exercise/products/readme.html",
    "href": "starter-analysis-exercise/products/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "The folders inside this folder should contain all the products of your project.\nFor a classical academic project, this will be a peer-reviewed manuscript, and should be placed into a manuscript folder.\nFor our case, since we’ll want to put it on the website, we call it a report.\nOften you need a library of references in bibtex format, as well as a CSL style file that determines reference formatting. Since those files might be used by several of the products, I’m placing them in the main products folder. Feel free to re-organize."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "Welcome!\n\nMy name is Taylor Glass.\nWelcome to my website and data analysis portfolio for the Modern Applied Data Analysis course at the University of Georgia.\n\nPlease use the Menu Bar above to look around.\nI have added information about me, and I plan to add examples of my work from this course as the semester progresses.\nStay tuned for more updates and content!"
  },
  {
    "objectID": "tidytuesday-exercise/tidytuesday-exercise.html",
    "href": "tidytuesday-exercise/tidytuesday-exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "Placeholder file for the future Tidy Tuesday exercise."
  },
  {
    "objectID": "coding-exercise/coding-exercise.html",
    "href": "coding-exercise/coding-exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "Placeholder file for the future R coding exercise."
  },
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About Me",
    "section": "",
    "text": "The Basics\nI am currently in the graduate year for my Master of Public Health in Biostatistics, so I have been living in Athens for over 4 years now. I am a Double Dawg here at the University of Georgia, and I have a bachelor’s of science in Health Promotion, which allowed me to get a head start on my MPH. I took my first biostatistics class during my freshman year, and I have been excited to learn more about this topic ever since. I chose this area of emphasis because I love combining my affinity for math with real public health problems. I really enjoy data visualization and translating findings from research studies into a format that can be understood by everyone. I hope to have a career that allows me to use my data analysis skills on projects that make a positive difference in population health.\n\n\nResearch Interests\nI am currently on Dr. Lambert and Dr. Swartzendruber’s research team working on their Crisis Pregnancy Center map. I completed my undergraduate internship with this team, and I spent most of my time completing qualitative data collection forms and developing codebooks. I continued my work in the fall of 2023 as the co-team leader for the content analysis team, which required me to manage 6 research assistants and complete weekly quality assurance checks of the data collection surveys. I love working in reproductive health research, and I am also interested in exploring research in the antimicrobial resistance and clinical trials for drug development spaces in the future.\n\n\nData Analysis Experience\nMost of my data analysis training has been hands-on with the CPC map project through using tools such as REDCap. I took the EPID 7500 elective in the fall of 2023, which gave me a great foundation for working with R studio. I also took BIOS 8110 in the same semester, which is a categorical data analysis class that allowed me to explore more advanced statistical methods. Both of these courses included a final project that required using a real-world data set to formula research questions, clean the data to answer these questions, and create a report with the findings.\n\n\nGoals For The Course\nI hope to become more comfortable with learning new data analysis tools using the resources provided during this course. I am often initially intimidated when it comes to learning new software and techniques, so I want to become better at adapting to new analysis tools. I am new to Github, so I am excited to create a presence in that space while learning how to utilize Gitkracken. While I have used AI tools sparingly, I am also looking forward to understanding more about how they function and how they can help me in my future career.\n\n\nFun Facts\nI am a huge foodie, so I spend the majority of my day planning meals, brainstorming ideas for the next party spread, or planning vacations to hot spots with new restaurants. Some of my favorite restaurants in Athens are Last Resort Grill, Thai Spoon, and Maepole. I love watching the Dawgs play, and I think game days are my favorite time to be in Athens. One unique thing about me is that I have the same birthday as my best friend, and we have spent the past 16 years celebrating together. Something curious about me: I actually grew up as an Auburn fan because my dad went there, but I will be cheering for the Dawgs from now on.\n\n\n\nMe in NYC at my favorite restaurant, Via Carota\n\n\n\n\nInteresting Data Analysis Predictions\nUpside is a website run by The Data Warehousing Institute with the majority of articles written by professional technology authors and some contributions from those within the data analytics community. A recently published article predicted the upcoming trends for generative AI in 2024. The most interesting prediction suggests an expansion of generative AI to support customer service with only meager large-scale investments in AI due to data security concerns. Additional topics discussed in the article include data lakehouses, Microsoft Fabric, and cloud analytics. I find the new platforms and companies involved in each of these data analysis topics to be really interesting because involvement in AI seems to be the hottest topic in current events recently."
  },
  {
    "objectID": "presentation-exercise/presentation-exercise.html",
    "href": "presentation-exercise/presentation-exercise.html",
    "title": "Presentation Exercise",
    "section": "",
    "text": "Placeholder file for the future data/results presentation exercise."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "",
    "text": "The structure below is one possible setup for a data analysis project (including the course project). For a manuscript, adjust as needed. You don’t need to have exactly these sections, but the content covering those sections should be addressed.\nThis uses MS Word as output format. See here for more information. You can switch to other formats, like html or pdf. See the Quarto documentation for other formats."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#general-background-information",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.1 General Background Information",
    "text": "3.1 General Background Information\nProvide enough background on your topic that others can understand the why and how of your analysis"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#description-of-data-and-data-source",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.2 Description of data and data source",
    "text": "3.2 Description of data and data source\nDescribe what the data is, what it contains, where it is from, etc. Eventually this might be part of a methods section."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#questionshypotheses-to-be-addressed",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "3.3 Questions/Hypotheses to be addressed",
    "text": "3.3 Questions/Hypotheses to be addressed\nState the research questions you plan to answer with this analysis.\nTo cite other work (important everywhere, but likely happens first in introduction), make sure your references are in the bibtex file specified in the YAML header above (here dataanalysis_template_references.bib) and have the right bibtex key. Then you can include like this:\nExamples of reproducible research projects can for instance be found in (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, Shen, & Handel, 2020)"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-aquisition",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.1 Data aquisition",
    "text": "4.1 Data aquisition\nAs applicable, explain where and how you got the data. If you directly import the data from an online source, you can combine this section with the next."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#data-import-and-cleaning",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.2 Data import and cleaning",
    "text": "4.2 Data import and cleaning\nWrite code that reads in the file and cleans it so it’s ready for analysis. Since this will be fairly long code for most datasets, it might be a good idea to have it in one or several R scripts. If that is the case, explain here briefly what kind of cleaning/processing you do, and provide more details and well documented code somewhere (e.g. as supplement in a paper). All materials, including files that contain code, should be commented well so everyone can follow along."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "4.3 Statistical analysis",
    "text": "4.3 Statistical analysis\nExplain anything related to your statistical analyses."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#exploratorydescriptive-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.1 Exploratory/Descriptive analysis",
    "text": "5.1 Exploratory/Descriptive analysis\nUse a combination of text/tables/figures to explore and describe your data. Show the most important descriptive results here. Additional ones should go in the supplement. Even more can be in the R and Quarto files that are part of your project.\nTable 1 shows a summary of the data.\nNote the loading of the data providing a relative path using the ../../ notation. (Two dots means a folder up). You never want to specify an absolute path like C:\\ahandel\\myproject\\results\\ because if you share this with someone, it won’t work for them since they don’t have that path. You can also use the here R package to create paths. See examples of that below. I recommend the here package, but I’m showing the other approach here just in case you encounter it.\n\n\n\n\nTable 1: Data summary table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_type\nskim_variable\nn_missing\ncomplete_rate\ncharacter.min\ncharacter.max\ncharacter.empty\ncharacter.n_unique\ncharacter.whitespace\nfactor.ordered\nfactor.n_unique\nfactor.top_counts\nnumeric.mean\nnumeric.sd\nnumeric.p0\nnumeric.p25\nnumeric.p50\nnumeric.p75\nnumeric.p100\nnumeric.hist\n\n\n\n\ncharacter\nRace\n0\n1\n1\n4\n0\n4\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nfactor\nGender\n0\n1\nNA\nNA\nNA\nNA\nNA\nFALSE\n3\nM: 4, F: 3, O: 2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\nnumeric\nHeight\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n165.66667\n15.97655\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nnumeric\nWeight\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n70.11111\n21.24526\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nnumeric\nAge\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n42.77778\n20.18525\n16\n23\n45\n51\n77\n▆▁▇▂▂"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#basic-statistical-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.2 Basic statistical analysis",
    "text": "5.2 Basic statistical analysis\nTo get some further insight into your data, if reasonable you could compute simple statistics (e.g. simple models with 1 predictor) to look for associations between your outcome(s) and each individual predictor variable. Though note that unless you pre-specified the outcome and main exposure, any “p&lt;0.05 means statistical significance” interpretation is not valid.\nFigure 1 shows a scatterplot figure produced by one of the R scripts.\n\n\n\n\n\n\n\n\nFigure 1: Height and weight stratified by gender.\n\n\n\n\n\nFigure 2 shows a boxplot figure produced by one of the R scripts. Each boxplot represents the distribution of height for a specific race. The average height is highest among Black participants, and average height seems to be approximately the same across the other three races included, which are White, American Indian and Alaska Native, and Asian. The boxplot for American Indian and Alaska Native is not helpful because there is only one observation for this racial category, so there is no additional data to display besides the height of the one AIAN observation.\n\n\n\n\n\n\n\n\nFigure 2: Height statified by race.\n\n\n\n\n\nFigure 3 shows a scatterplot figure produced by one of the R scripts. The scatterplot has been fitted with a line that displays the relationship between the two numerical variables along with a shaded area that represents the confidence interval around the estimates. As weight increases across the x-axis, age decreases. This observation is counter intuitive because most people gain weight as they age, which suggests there could be an issue with the data.\n\n\n\n\n\n\n\n\nFigure 3: Plot of age by weight."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#full-analysis",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "5.3 Full analysis",
    "text": "5.3 Full analysis\nUse one or several suitable statistical/machine learning methods to analyze your data and to produce meaningful figures, tables, etc. This might again be code that is best placed in one or several separate R scripts that need to be well documented. You want the code to produce figures and data ready for display as tables, and save those. Then you load them here.\nExample Table 2 shows a summary of a linear model fit.\n\n\n\n\nTable 2: Linear model fit table.\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n149.2726967\n23.3823360\n6.3839942\n0.0013962\n\n\nWeight\n0.2623972\n0.3512436\n0.7470519\n0.4886517\n\n\nGenderM\n-2.1244913\n15.5488953\n-0.1366329\n0.8966520\n\n\nGenderO\n-4.7644739\n19.0114155\n-0.2506112\n0.8120871\n\n\n\n\n\n\n\n\nExample Table 3 shows a summary of another linear model fit with Height as the outcome with Race and Age as predictors. The table displays an estimate for each component of the linear model, along with the standard error, test statistic, and p-value for the estimate to provide context for its usefulness. The p-values for each variable are extremely large, which shows we fail to reject the null hypothesis that each of these variables are not statistically significantly associated with height according to this dataset.\n\n\n\n\nTable 3: Second linear model fit table.\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n167.5410539\n20.2483086\n8.2743234\n0.0011643\n\n\nRaceAIAN\n-0.5460615\n26.1275182\n-0.0208999\n0.9843265\n\n\nRaceB\n-1.1524256\n18.6903702\n-0.0616588\n0.9537925\n\n\nRaceW\n-2.0799817\n20.6436086\n-0.1007567\n0.9245919\n\n\nAge\n-0.0226135\n0.4010505\n-0.0563856\n0.9577388"
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#summary-and-interpretation",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "6.1 Summary and Interpretation",
    "text": "6.1 Summary and Interpretation\nSummarize what you did, what you found and what it means."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#strengths-and-limitations",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "6.2 Strengths and Limitations",
    "text": "6.2 Strengths and Limitations\nDiscuss what you perceive as strengths and limitations of your analysis."
  },
  {
    "objectID": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "href": "starter-analysis-exercise/products/report/starter-analysis-report.html#conclusions",
    "title": "Manuscript/Report Template for a Data Analysis Project",
    "section": "6.3 Conclusions",
    "text": "6.3 Conclusions\nWhat are the main take-home messages?\nInclude citations in your Rmd file using bibtex, the list of references will automatically be placed at the end\nThis paper (Leek & Peng, 2015) discusses types of analyses.\nThese papers (McKay, Ebell, Billings, et al., 2020; McKay, Ebell, Dale, et al., 2020) are good examples of papers published using a fully reproducible setup similar to the one shown in this template.\nNote that this cited reference will show up at the end of the document, the reference formatting is determined by the CSL file specified in the YAML header. Many more style files for almost any journal are available. You also specify the location of your bibtex reference file in the YAML. You can call your reference file anything you like, I just used the generic word references.bib but giving it a more descriptive name is probably better."
  },
  {
    "objectID": "starter-analysis-exercise/code/readme.html",
    "href": "starter-analysis-exercise/code/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "Place your various R or Quarto files in the appropriate folders.\nYou can either have fewer large scripts, or multiple scripts that do only specific actions. Those can be R or Quarto files. In either case, document the scripts and what goes on in them so well that someone else (including future you) can easily figure out what is happening.\nThe scripts should load the appropriate data (e.g. raw or processed), perform actions, and save results (e.g. processed data, figures, computed values) in the appropriate folders. Document somewhere what inputs each script takes and where output is placed.\nIf scripts need to be run in a specific order, document this. Either as comments in the script, or in a separate text file such as this readme file. Ideally of course in both locations.\nDepending on your specific project, you might want to have further folders/sub-folders."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/readme.html",
    "href": "starter-analysis-exercise/code/eda-code/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code to do some simple exploratory data analysis (EDA) on the processed/cleaned data. The code produces a few tables and figures, which are saved in the appropriate results sub-folder."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/readme.html",
    "href": "starter-analysis-exercise/code/processing-code/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains code for processing data.\nCurrently, there is just a single Quarto file to illustrate how the processing can look like.\nInstead of a Quarto file that contains code, it is also possible to use R scripts or a combination of R scripts and Quarto code. Those approaches are illustrated in the full dataanalysis-template repository."
  },
  {
    "objectID": "starter-analysis-exercise/results/readme.html",
    "href": "starter-analysis-exercise/results/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains results produced by the code, such as figures and tables.\nDepending on the size and type of your project, you can either place it all in a single folder or create sub-folders. For instance you could create a folder for figures, another for tables. Or you could create a sub-folder for dataset 1, another for dataset 2. Or you could have a subfolder for exploratory analysis, another for final analysis. The options are endless, choose whatever makes sense for your project. For this template, there is just a a single folder, but having sub-folders is often a good idea."
  },
  {
    "objectID": "starter-analysis-exercise/data/raw-data/readme.html",
    "href": "starter-analysis-exercise/data/raw-data/readme.html",
    "title": "Taylor Glass Data Analysis Portfolio",
    "section": "",
    "text": "This folder contains a simple made-up data-set in an Excel file.\nIt contains the variables Height, Weight and Gender of a few imaginary individuals.\nThe dataset purposefully contains some faulty entries that need to be cleaned.\nGenerally, any dataset should contain some meta-data explaining what each variable in the dataset is. (This is often called a Codebook.) For this simple example, the codebook is given as a second sheet in the Excel file.\nThis raw data-set should generally not be edited by hand. It should instead be loaded and processed/cleaned using code."
  },
  {
    "objectID": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "href": "starter-analysis-exercise/code/processing-code/processingfile2.html",
    "title": "An example cleaning script",
    "section": "",
    "text": "Processing script\nThis Quarto file contains a mix of code and explanatory text to illustrate a simple data processing/cleaning setup.\n\n\nSetup\nLoad needed packages. make sure they are installed.\n\nlibrary(readxl) #for loading Excel files\nlibrary(dplyr) #for data processing/cleaning\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(tidyr) #for data processing/cleaning\nlibrary(skimr) #for nice visualization of data \nlibrary(here) #to set paths\n\nhere() starts at /Users/taylorglass/Documents/MADA /taylorglass-MADA-portfolio\n\n\n\n\nData loading\nNote that for functions that come from specific packages (instead of base R), I often specify both package and function like so: package::function() that’s not required one could just call the function specifying the package makes it clearer where the function “lives”, but it adds typing. You can do it either way.\n\n# path to data\n# note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"raw-data\",\"exampledata2.xlsx\")\nrawdata &lt;- readxl::read_excel(data_location)\n\n\n\nCheck data\nFirst we can look at the codebook\n\ncodebook &lt;- readxl::read_excel(data_location, sheet =\"Codebook\")\nprint(codebook)\n\n# A tibble: 5 × 3\n  `Variable Name` `Variable Definition`                         `Allowed Values`\n  &lt;chr&gt;           &lt;chr&gt;                                         &lt;chr&gt;           \n1 Height          height in centimeters                         numeric value &gt;…\n2 Weight          weight in kilograms                           numeric value &gt;…\n3 Gender          identified gender (male/female/other)         M/F/O/NA        \n4 Race            Identified  race (black/white/American India… B/W/AIAN/A      \n5 Age             age in years                                  numeric value &gt;…\n\n\nSeveral ways of looking at the data\n\ndplyr::glimpse(rawdata)\n\nRows: 14\nColumns: 5\n$ Height &lt;chr&gt; \"180\", \"175\", \"sixty\", \"178\", \"192\", \"6\", \"156\", \"166\", \"155\", …\n$ Weight &lt;dbl&gt; 80, 70, 60, 76, 90, 55, 90, 110, 54, 7000, NA, 45, 55, 50\n$ Gender &lt;chr&gt; \"M\", \"O\", \"F\", \"F\", \"NA\", \"F\", \"O\", \"M\", \"N\", \"M\", \"F\", \"F\", \"M…\n$ Race   &lt;chr&gt; \"B\", \"W\", \"AIAN\", \"A\", \"B\", \"B\", \"A\", \"AIAN\", \"W\", \"W\", \"W\", \"B…\n$ Age    &lt;dbl&gt; 16, 23, 19, 45, 56, 77, 20, 44, 32, 21, 39, 47, 51, 62\n\nsummary(rawdata)\n\n    Height              Weight          Gender              Race          \n Length:14          Min.   :  45.0   Length:14          Length:14         \n Class :character   1st Qu.:  55.0   Class :character   Class :character  \n Mode  :character   Median :  70.0   Mode  :character   Mode  :character  \n                    Mean   : 602.7                                        \n                    3rd Qu.:  90.0                                        \n                    Max.   :7000.0                                        \n                    NA's   :1                                             \n      Age       \n Min.   :16.00  \n 1st Qu.:21.50  \n Median :41.50  \n Mean   :39.43  \n 3rd Qu.:50.00  \n Max.   :77.00  \n                \n\nhead(rawdata)\n\n# A tibble: 6 × 5\n  Height Weight Gender Race    Age\n  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n1 180        80 M      B        16\n2 175        70 O      W        23\n3 sixty      60 F      AIAN     19\n4 178        76 F      A        45\n5 192        90 NA     B        56\n6 6          55 F      B        77\n\nskimr::skim(rawdata)\n\n\nData summary\n\n\nName\nrawdata\n\n\nNumber of rows\n14\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nHeight\n0\n1\n1\n5\n0\n13\n0\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nRace\n0\n1\n1\n4\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nWeight\n1\n0.93\n602.69\n1922.25\n45\n55.0\n70.0\n90\n7000\n▇▁▁▁▁\n\n\nAge\n0\n1.00\n39.43\n18.50\n16\n21.5\n41.5\n50\n77\n▇▃▆▃▂\n\n\n\n\n\n\n\nCleaning\nBy inspecting the data as done above, we find some problems that need addressing:\nFirst, there is an entry for height which says “sixty” instead of a number. Does that mean it should be a numeric 60? It somehow doesn’t make sense since the weight is 60kg, which can’t happen for a 60cm person (a baby). Since we don’t know how to fix this, we might decide to remove the person. This “sixty” entry also turned all Height entries into characters instead of numeric. That conversion to character also means that our summary function isn’t very meaningful. So let’s fix that first.\n\nd1 &lt;- rawdata %&gt;% dplyr::filter( Height != \"sixty\" ) %&gt;% \n                  dplyr::mutate(Height = as.numeric(Height))\nskimr::skim(d1)\n\n\nData summary\n\n\nName\nd1\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nRace\n0\n1\n1\n4\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n151.62\n46.46\n6\n154.00\n165\n175\n192\n▁▁▁▂▇\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nAge\n0\n1.00\n41.00\n18.25\n16\n23.00\n44\n51\n77\n▇▃▇▃▂\n\n\n\n\nhist(d1$Height)\n\n\n\n\n\n\n\n\nNow we see that there is one person with a height of 6. That could be a typo, or someone mistakenly entered their height in feet. Since we unfortunately don’t know, we might need to remove this person, which we’ll do here.\n\nd2 &lt;- d1 %&gt;% dplyr::mutate( Height = replace(Height, Height==\"6\",round(6*30.48,0)) )\nskimr::skim(d2)\n\n\nData summary\n\n\nName\nd2\n\n\nNumber of rows\n13\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nRace\n0\n1\n1\n4\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1.00\n165.23\n16.52\n133\n155.00\n166\n178\n192\n▂▇▆▆▃\n\n\nWeight\n1\n0.92\n647.92\n2000.48\n45\n54.75\n73\n90\n7000\n▇▁▁▁▁\n\n\nAge\n0\n1.00\n41.00\n18.25\n16\n23.00\n44\n51\n77\n▇▃▇▃▂\n\n\n\n\n\nHeight values seem ok now.\nNow let’s look at the Weight variable. There is a person with weight of 7000, which is impossible, and one person with missing weight. To be able to analyze the data, we’ll remove those individuals as well.\n\nd3 &lt;- d2 %&gt;%  dplyr::filter(Weight != 7000) %&gt;% tidyr::drop_na()\nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nGender\n0\n1\n1\n2\n0\n5\n0\n\n\nRace\n0\n1\n1\n4\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179.0\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85.0\n110\n▇▂▃▃▂\n\n\nAge\n0\n1\n43.00\n18.84\n16\n27.5\n45\n53.5\n77\n▆▂▇▃▂\n\n\n\n\n\nNow checking the Gender variable. Gender should be a categorical/factor variable but is loaded as character. We can fix that with simple base R code to mix things up.\n\nd3$Gender &lt;- as.factor(d3$Gender)  \nskimr::skim(d3)\n\n\nData summary\n\n\nName\nd3\n\n\nNumber of rows\n11\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nRace\n0\n1\n1\n4\n0\n4\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n5\nM: 4, F: 3, O: 2, N: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n167.09\n16.81\n133\n155.5\n166\n179.0\n192\n▂▇▅▇▅\n\n\nWeight\n0\n1\n70.45\n20.65\n45\n54.5\n70\n85.0\n110\n▇▂▃▃▂\n\n\nAge\n0\n1\n43.00\n18.84\n16\n27.5\n45\n53.5\n77\n▆▂▇▃▂\n\n\n\n\n\nNow we see that there is another NA, but it’s not NA from R, instead it was loaded as character and is now considered as a category. Well proceed here by removing that individual with that NA entry. Since this keeps an empty category for Gender, I’m also using droplevels() to get rid of it.\n\nd4 &lt;- d3 %&gt;% dplyr::filter( !(Gender %in% c(\"NA\",\"N\")) ) %&gt;% droplevels()\nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nfactor\n1\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nRace\n0\n1\n1\n4\n0\n4\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nAge\n0\n1\n42.78\n20.19\n16\n23\n45\n51\n77\n▆▁▇▂▂\n\n\n\n\n\n Additional cleaning on updated raw data. Age variable treated as numeric (good). No glaring issues with values. Notice variable Race is categorical, but is treated as character by R. Let’s fix that. \n\nd4$Race &lt;- as.factor(d4$Race)  \nskimr::skim(d4)\n\n\nData summary\n\n\nName\nd4\n\n\nNumber of rows\n9\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n0\n1\nFALSE\n3\nM: 4, F: 3, O: 2\n\n\nRace\n0\n1\nFALSE\n4\nA: 3, B: 3, W: 2, AIA: 1\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nHeight\n0\n1\n165.67\n15.98\n133\n156\n166\n178\n183\n▂▁▃▃▇\n\n\nWeight\n0\n1\n70.11\n21.25\n45\n55\n70\n80\n110\n▇▂▃▂▂\n\n\nAge\n0\n1\n42.78\n20.19\n16\n23\n45\n51\n77\n▆▁▇▂▂\n\n\n\n\n\n Race variable is now treated as categorical (good). No glaring issues with values. \nAll done, data is clean now.\nLet’s assign at the end to some final variable, this makes it easier to add further cleaning steps above.\n\nprocesseddata &lt;- d4\n\n\n\nSave data\nFinally, we save the clean data as RDS file. I suggest you save your processed and cleaned data as RDS or RDA/Rdata files. This preserves coding like factors, characters, numeric, etc. If you save as CSV, that information would get lost. However, CSV is better for sharing with others since it’s plain text. If you do CSV, you might want to write down somewhere what each variable is.\nSee here for some suggestions on how to store your processed data: http://www.sthda.com/english/wiki/saving-data-into-r-data-format-rds-and-rdata\n\nsave_data_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata2.rds\")\nsaveRDS(processeddata, file = save_data_location)\n\nNote the use of the here package and here command to specify a path relative to the main project directory, that is the folder that contains the .Rproj file. Always use this approach instead of hard-coding file paths that only exist on your computer.\n\n\nNotes\nRemoving anyone observation with “faulty” or missing data is one approach. It’s often not the best. based on your question and your analysis approach, you might want to do cleaning differently (e.g. keep observations with some missing information)."
  },
  {
    "objectID": "starter-analysis-exercise/code/eda-code/eda2.html",
    "href": "starter-analysis-exercise/code/eda-code/eda2.html",
    "title": "An example exploratory analysis script",
    "section": "",
    "text": "This Quarto file loads the cleaned data and does some exploring.\nI’m only showing it the way where the code is included in the file. As described in the processing_code materials, I currently prefer the approach of having R code in a separate file and pulling it in.\nBut I already had this written and haven’t yet re-done it that way. Feel free to redo and send a pull request on GitHub :)\nAgain, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files. And sometimes, an R script with enough comments is good enough and one doesn’t need a Quarto file.\nAlso note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you’ll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.\nAs part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.\nStart by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables.\nPlots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.\n\nSetup\n\n#load needed packages. make sure they are installed.\nlibrary(here) #for data loading/saving\n\nhere() starts at /Users/taylorglass/Documents/MADA /taylorglass-MADA-portfolio\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(skimr)\nlibrary(ggplot2)\n\nLoad the data.\n\n#Path to data. Note the use of the here() package and not absolute paths\ndata_location &lt;- here::here(\"starter-analysis-exercise\",\"data\",\"processed-data\",\"processeddata2.rds\")\n#load data\nmydata &lt;- readRDS(data_location)\n\n\n\nData exploration through tables\nShowing a bit of code to produce and save a summary table.\n\nsummary_df = skimr::skim(mydata)\nprint(summary_df)\n\n── Data Summary ────────────────────────\n                           Values\nName                       mydata\nNumber of rows             9     \nNumber of columns          5     \n_______________________          \nColumn type frequency:           \n  factor                   2     \n  numeric                  3     \n________________________         \nGroup variables            None  \n\n── Variable type: factor ───────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique\n1 Gender                0             1 FALSE          3\n2 Race                  0             1 FALSE          4\n  top_counts              \n1 M: 4, F: 3, O: 2        \n2 A: 3, B: 3, W: 2, AIA: 1\n\n── Variable type: numeric ──────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate  mean   sd  p0 p25 p50 p75 p100 hist \n1 Height                0             1 166.  16.0 133 156 166 178  183 ▂▁▃▃▇\n2 Weight                0             1  70.1 21.2  45  55  70  80  110 ▇▂▃▂▂\n3 Age                   0             1  42.8 20.2  16  23  45  51   77 ▆▁▇▂▂\n\n# save to file\nsummarytable_file = here(\"starter-analysis-exercise\",\"results\", \"tables-files\", \"summarytable2.rds\")\nsaveRDS(summary_df, file = summarytable_file)\n\nWe are saving the results to the results/tables folder. Structure the folders inside results such that they make sense for your specific analysis. Provide enough documentation that someone can understand what you are doing and what goes where. readme.md files inside each folder are a good idea.\n\n\nData exploration through figures\nHistogram plots for the continuous outcomes.\nHeight first.\n\np1 &lt;- mydata %&gt;% ggplot(aes(x=Height)) + geom_histogram() \nplot(p1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-distribution.png\")\nggsave(filename = figure_file, plot=p1) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow weights.\n\np2 &lt;- mydata %&gt;% ggplot(aes(x=Weight)) + geom_histogram() \nplot(p2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"weight-distribution.png\")\nggsave(filename = figure_file, plot=p2) \n\nSaving 7 x 5 in image\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nNow height as function of weight.\n\np3 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight)) + geom_point() + geom_smooth(method='lm')\nplot(p3)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight.png\")\nggsave(filename = figure_file, plot=p3) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nOnce more height as function of weight, stratified by gender. Note that there is so little data, it’s a bit silly. But we’ll plot it anyway.\n\np4 &lt;- mydata %&gt;% ggplot(aes(x=Height, y=Weight, color = Gender)) + geom_point() + geom_smooth(method='lm')\nplot(p4)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-weight-stratified.png\")\nggsave(filename = figure_file, plot=p4) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning in qt((1 - level)/2, df): NaNs produced\n\nWarning in qt((1 - level)/2, df): no non-missing arguments to max; returning\n-Inf\n\n\n Boxplot of Height variable by Race. \n\np5 &lt;- ggplot() + geom_boxplot(data = mydata, aes(x = Race, y = Height)) + \n  labs(title = \"Boxplot summary of height by race\")\nplot(p5)\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"height-race-stratified.png\")\nggsave(filename = figure_file, plot=p5) \n\nSaving 7 x 5 in image\n\n\n Note about boxplot of Race variable against Height: there is only one observation of AIAN factor level, reflected by single horizontal line for its boxplot. \n Scatterplot of Age variable against Weight variable. \n\np6 &lt;- ggplot() + geom_point(data = mydata, aes(x = Weight, y = Age)) + geom_smooth(data = mydata, aes(x = Weight, y = Age), method = 'lm') + labs(title = \"Plot of age by weight\")\nplot(p6)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nfigure_file = here(\"starter-analysis-exercise\",\"results\",\"figures\",\"age-weight.png\")\nggsave(filename = figure_file, plot=p6) \n\nSaving 7 x 5 in image\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\nNotes\nFor your own explorations, tables and figures can be “quick and dirty”. As long as you can see what’s going on, there is no need to polish them. That’s in contrast to figures you’ll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "",
    "text": "Brian McKay1, Department of Epidemiology and Biostatistics, The University of Georgia, Athens, GA, USA\nMark Ebell, Department of Epidemiology and Biostatistics, The University of Georgia, Athens, GA, USA\nAriella Perry Dale, Colorado Department of Public Health and Environment, Denver, CO, USA\nYe Shen, Department of Epidemiology and Biostatistics, The University of Georgia, Athens, GA, USA\nAndreas Handel1, Department of Epidemiology and Biostatistics, The University of Georgia, Athens, GA, USA\n\n1 Corresponding Authors: Brian McKay and Andreas Handel\nAddress: 101 Buck Rd, Miller Hall, Athens, Georgia 30606\nEmail: bmckay52@uga.edu or ahandel@uga.edu"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#data-collection",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#data-collection",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Data Collection",
    "text": "Data Collection\nStudents with a primary complaint related to a respiratory infection who made an appointment at the health center of a large research university from December 2016 to February 2017 filled out an electronic questionnaire (see [27] for more details). The questionnaire collected data about their current symptoms and activity level. A response was required for all symptom-related questions when they scheduled their appointments. We included all symptoms collected by the questionnaire in this analysis. The complete questionnaire is available in the supplementary material.\nFor the symptoms of cough, weakness, and body aches, the patient graded the severity of the symptom as none, mild, moderate, and severe. The patient recorded all other symptom data as present or absent. The patient also reported any changes in their normal behavior. Patients describe their activity level as a number between 0 and 10, with 10 indicating no change in regular activity and 0 being bedridden.\nThe study population includes all patients with a diagnosis of influenza. The data and results presented in the main text includes patients diagnosed with a rapid antigen or rapid PCR test. To address the impact of the influenza diagnosis method, we performed the same analyses for all patients diagnosed with influenza regardless of the method used. These results are shown in the supplementary material.\nThe institutional review board approved the study protocol."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#data-cleaning",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#data-cleaning",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Data Cleaning",
    "text": "Data Cleaning\nWe cleaned the data to format the variables and to check for variables with potential errors or missing entries. During the cleaning process, we removed uninformative variables, which we defined as any symptoms found to occur in less than 5% of patients. The symptoms of blurred vision and hearing loss both had a prevalence of less than 5%, so they were not considered for further analysis. To allow easy comparison of morbidity symptoms, we dichotomized weakness and body aches to “absent” or “present”. Patients reported cough as present or absent as well as severity, but only cough absent or present was considered for the main analysis."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#analysis",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#analysis",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Analysis",
    "text": "Analysis\nWe assessed the univariate relationships between activity and each symptom using linear regression treating activity level as a continuous variable. We also performed multiple linear regression. We determined the variables to include in our final model with a sequential forward floating selection, minimizing the root mean square error (RMSE) on test data through a 5-fold cross-validation (20 times repeated) [28].\nNext, we constructed two cumulative scores, one for overall infectiousness and one for overall morbidity. To that end, we divided all symptoms into those related to infectiousness and those related to morbidity (SM Table 1). We defined morbidity symptoms as symptoms that influence overall feelings of well-being but are not associated with infectiousness. Infectiousness symptoms are any symptoms that could plausibly contribute to passing the virus from an infected host to a susceptible host [29,30]. Importantly, the grouping of variables into either the morbidity or infectiousness symptom categories was based on a priori medical and biologic considerations, independently of any observed correlation with activity level. Doing so prevents any circular reasoning since only including symptoms correlated with activity would, of course, generate a score which would match the impact on activity level. These scores are similar to systemic and respiratory scores used in past studies of influenza infection [29,31,32]. The scores are computed as a sum of the symptoms that are present. Our data did not allow us to take into account symptom severity, though a comparison of our scores with cough, weakness, and body aches, for which we have severity, shows that there is a good positive correlation between strength and number of symptoms (see SM). To test the robustness of our results, we completed several sensitivity analyses using different approaches to generate the scores. Results from these analyses are shown in the SM.\nCorrelations between the infectiousness score, morbidity score, and activity were assessed using Spearman correlation [33] and the generalized Mantel–Haenszel procedure [34]. Linear regression is used to estimate the average change in activity, and the lines are included in the plots to help visualize the relationships. All analyses were completed using R (version 3.5.3) [35]. We used the mlr package for cross-validation [36], vcdExtra to compute Yule’s Q and the CHM trend test [37], DescTools to compute Spearman’s rank correlation coefficient and corresponding confidence intervals [38]. All of the code and data required to reproduce the results are available through Dryad."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#study-population",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#study-population",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Study population",
    "text": "Study population\nDuring the study period, 2380 patients had a respiratory complaint and filled out the questionnaire. Among those, 324 had a lab-based diagnosis of influenza (PCR or rapid antigen). The following analyses focus on those patients since they are most likely infected with influenza. For analyses of patients who received a flu diagnosis based on lab tests or empirically from a physician, see the SM. Patients with influenza reported activity levels ranging from 0 to 10 with a median of 4 (SM Figure 1). All of the patients reported symptoms, with only 14% reporting 9 or fewer (max possible 25). The most common symptoms were coughing and weakness while the least common was abdominal pain (SM Table 1)."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#univariate-and-subset-selection",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#univariate-and-subset-selection",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Univariate and subset selection",
    "text": "Univariate and subset selection\nWe assessed correlations between activity level and each symptom in a univariate linear analysis (SM Table 2). All statistically significant symptoms had a negative correlation with activity level (SM Table 2). Next, we considered a multi-variable regression model and performed variable selection based on cross-validated minimization of RMSE. We found that the best performing model was one that included chills/sweats, subjective fever, headache, weakness, sleeplessness, and vomiting (SM Table 2). While vomiting is not a common symptom of influenza, in those patients who did report vomiting lead to major reductions in their activity."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#computation-of-infectiousness-and-morbidity-scores",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#computation-of-infectiousness-and-morbidity-scores",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Computation of infectiousness and morbidity scores",
    "text": "Computation of infectiousness and morbidity scores\nFor the main analysis, we classified 5 symptoms as infectiousness related: coughing, sneezing, runny nose, nasal congestion, and chest congestion. 20 symptoms were classified as morbidity related: subjective fever, having chills and or sweats, body aches, weakness, headache, fatigue, sleeplessness, breathlessness, wheezing, chest pain, sore throat, abdominal pain, diarrhea, nausea, vomiting, ear pain, tooth pain, eye pain, itchy eyes, and swollen lymph nodes. Each symptom present in a patient contributed one point to their respective scores. For those symptoms for which we had severity, we investigated correlations with number of symptoms and found total number of symptoms to be a good proxy (see SM). Analyses using several alternative approaches for computing the score are shown in the SM and summarized below in the Sensitivity Analysis section.\nThe infectiousness score had a possible range of 0 to 5, and the morbidity score had a possible range of 0 to 20. The median infectiousness score was 4. Only 2 patients had an infectiousness score of 0, 20% had a score of 2 or less, and 28% of patients had the maximum possible score of 5. The mean morbidity score was 9.574, and no patients had a morbidity score of 0, 1, 19 or 20. The centered distribution is assumed to be the result of how patients were included in the study that is all the patients felt sick enough to seek medical care, but none were sick enough to require urgent care or hospitalization. Results presented in the SM show plots of the score distributions (SM Figure 2 A-B)."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#impact-of-infectiousness-score-on-activity",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#impact-of-infectiousness-score-on-activity",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Impact of infectiousness score on activity",
    "text": "Impact of infectiousness score on activity\nAnalysis of the association between the infectiousness score and the patient’s self-reported activity level suggests that the value of this score has a small impact on the activity level of a patient, with higher infectiousness correlating with reduced activity. Spearman’s rank correlation indicates a negative relationship (\\(r=\\) -0.15 (95% CI: -0.25, -0.04)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 6.363, \\(df =\\) 1, \\(p\\) 0.01) (Figure @ref(fig:LabMIvAFig)A). Note however that the data suggest a non-linear relationship between infectiousness and activity. We cannot think of a biological mechanism that might lead to this pattern. Given that the observed negative trend is small and doesn’t show a monotone decline, it is most reasonable to assume based on this data that there is no meaningful relationship between infectiousness score and activity level. Results presented in the SM show that the overall pattern remains the same if details of the analysis approach are changed (SM Figures 6-8B, 13)."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#impact-of-morbidity-score-on-activity",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#impact-of-morbidity-score-on-activity",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Impact of morbidity score on activity",
    "text": "Impact of morbidity score on activity\nAnalysis of the association between the morbidity score and the patient’s self-reported activity level suggests that higher morbidity score is associated with reduced activity levels. Spearman’s rank correlation indicates negative relationship (\\(r=\\) -0.32 (95% CI: -0.42, -0.22)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 38.577, \\(df =\\) 1, \\(p\\) &lt; 0.01) (Figure @ref(fig:LabMIvAFig)B). The observed pattern is consistent and clear, with a mean 4.7-fold reduction in activity level going from the lowest to the highest morbidity score. The strong negative relationship is preserved if details of the analysis approach are changed results are shown in SM (SM Figures 9-10B, 14)."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#impact-of-morbidity-score-on-infectiousness-score",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#impact-of-morbidity-score-on-infectiousness-score",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Impact of morbidity score on infectiousness score",
    "text": "Impact of morbidity score on infectiousness score\nAnalysis of the relationship between the morbidity and infectiousness scores show a positive correlation. Spearman’s rank correlation indicates positive relationship (\\(r=\\) 0.28 (95% CI: 0.18, 0.38)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 26.093, \\(df =\\) 1, \\(p\\) &lt; 0.01) (Figure @ref(fig:LabMIvAFig)C). Apart from the mean activity levels for very low morbidity score values (with very small sample sizes), the pattern is consistent and clear, with a mean 1.8-fold increase in the infectiousness score going from the lowest to the highest morbidity score. A positive relationship is observed regardless of how the infectiousness or morbidity scores are calculated (SM Figures 6-10C) and in the analysis of empirically-diagnosed patients (SM Figure 15).\n\n\n\n\n\nFor all plots the red diamonds indicate the mean and the solid blue line is the linear regression fit. The shaded area is the 95% confidence interval for the linear regression. (A) Activity level for each level of the infectiousness score. (B) Activity level for each level of the morbidity score. There are no patients with a score of morbidity 0, 1, 19, and 20. (C) Infectiousness score for each level of the morbidity score."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#sensitivity-analysis",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#sensitivity-analysis",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Sensitivity analysis",
    "text": "Sensitivity analysis\nWe performed several sensitivity analyses of our results. In one type of analysis, we computed both the morbidity and infectiousness scores in different ways and showed that overall results remain the same. In a different analysis, we considered all patients diagnosed with influenza, not just those that had a positive lab test. Again, overall results remained robust. Details of all these analyses are presented in the SM."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#conceptualizing-our-results",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/6 Manuscript/Manuscript.html#conceptualizing-our-results",
    "title": "Virulence-mediated infectiousness and activity trade-offs and their impact on transmission potential of influenza patients",
    "section": "Conceptualizing our results",
    "text": "Conceptualizing our results\nWe can place our data into the conceptual framework introduced in the introduction with the morbidity score as a proxy of virulence, \\(v\\), the infectiousness score as a proxy of per-contact transmission potential, \\(p\\), and patient-reported activity as a proxy for the contact rate, \\(c\\) (Figure @ref(fig:HypoFigDATA)). Since our data is measured in units with indirect and uncertain mapping to actual per-contact transmission potential and actual contact rate, we standardize the data and manually place it on top of the conceptual lines. This should not be considered a quantitative mapping.\nOur study population consisted of individuals who felt sick enough to seek medical care, but none were ill enough to require emergency care. It is thus a reasonable assumption to expect them to be somewhere in the middle of the virulence spectrum. Based on our data, this range is characterized by infectiousness levels that are increasing as morbidity (virulence) increases (Figure @ref(fig:HypoFigDATA)). Activity is more strongly impacted and decreases as morbidity increases. We speculate that a study population that included asymptomatic and mildly symptomatic infected persons would be on the left side of our data, while severely ill and hospitalized individuals would fall to the right side of our data.\n\n\n\n\n\nTheoretical framework and data for virulence mediated transmission trade-off. Morbidity score is a proxy for virulence, infectiousness score is a proxy for per-contact transmission potential, and activity level is a proxy for contact rate. The values for infectiousness and activity are re-scaled to allow better visualization. Lines are adjusted to pass through data. Thus, this figure does not show a fit but instead a conceptual framework in which our data can be placed and interpreted."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "",
    "text": "Brian McKay1, Department of Epidemiology and Biostatistics, The University of Georgia, Athens, GA, USA\nMark Ebell, Department of Epidemiology and Biostatistics, The University of Georgia, Athens, GA, USA\nAriella Perry, Colorado Department of Public Health and Environment, Denver, CO, USA\nYe Shen, Department of Epidemiology and Biostatistics, The University of Georgia, Athens, GA, USA\nAndreas Handel1, Department of Epidemiology and Biostatistics, The University of Georgia, Athens, GA, USA\n\n1 Corresponding Authors: Brian McKay and Andreas Handel\nAddress: 101 Buck Rd, Miller Hall, Athens, Georgia 30606\nEmail: bmckay52@uga.edu or ahandel@uga.edu\nPROCEEDINGS OF THE ROYAL SOCIETY B\nDOI: 10.1098/rspb.2020.0496"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#getting-the-files",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#getting-the-files",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Getting the files",
    "text": "Getting the files\nThe files described below are available from Dryad https://doi.org/10.5061/dryad.51c59zw4v.\n\n“Virulence_Trade-off.Rproj” This file lets R know the relative file paths for loading and saving files.\n“SymptomActivity.bib” This file has all of the citation saved as a bibTex.\n“Symptom Questionnaire_Redacted.pdf”: This is a copy of the electronic questionnaire patients with an upper respiratory symptoms were required to fill out. All identifying information has been redacted.\n“DataDictionary_VirulenceTradeOff.xlsx”: This document provides a description of all the variables included in the analysis.\n“1 Anonymized Data” folder contains the de-identified data for the analyses\n\nAn R script that merges all of the individual data sets and creates and saves “Data.Rda” and “Data.csv” in the “1 Anonymized Data” Folder. This script is not included since the raw data sets are not included to protect patient privacy.\n\n“2 Data Cleaning Script” folder contains one R script that cleans the data for the analyses\n\n“Data Merging Script.R”: R script that merges all of the individual data sets and creates and saves “Data.Rda” in the “1 Anonymized Data” Folder. This script is not included since the raw data sets are not included to protect patient privacy.\n“Data Cleaning.R”: This R script does all of the data preparation, creating all the required variables for the analysis. This script also produces the data sets used for the analyses and saves them in the “3 Clean Data” folder.\n\n“4 Analysis Scripts” folder has 4 R scripts that analyze the clean data and produce the results presented in the main text and supplement.\n\n“Flu Symptoms Activity Models.R” This script creates the univariate/multivariate linear regression table, the Spearman rank correlation, and the CMH trend tests. Results are saved in “5 Results”\n“Flu Symptoms Activity Plots.R” This script creates all of the plots. Results are saved in “5 Results”\n“Flu Symptoms Activity Tables.R” This script creates all of the tables. Results are saved in “5 Results”\n“Multivariate Subset Selection.R” This script does the variable selection for the multivariate model. Results are saved in “5 Results”\n\n“6 Manuscript” folder has 2 files in it used to create the manuscript.\n\n“Manuscript.Rmd” This Rmd file creates the basic manuscript word document (formatting will not be identical)\n“proceedings-of-the-royal-society-b.csl” is a style file to format the citations in the manuscript\n\n“7 Supplemental Material” folder has 2 files used to create this document\n\n“Supplemental Material.Rmd” This Rmd file creates the basic supplemental material word document (formatting will not be identical)\n“proceedings-of-the-royal-society-b.csl” is a style file to format the citations in the supplement"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#reproducing-results",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#reproducing-results",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Reproducing results",
    "text": "Reproducing results\nThe files required to reproduce the results are 2 R Markdown files, 4 R script, and one anonymized data file. These files allow the reproduction of all results shown in the main text and SM. To reproduce the results follow these steps.\nFirst, install R, Rstudio, and Pandoc (when you install Rstudio Pandoc should automatically install). Microsoft Word or Open Office Word is also required.\nSecond, save the zip file from Dryad on your local computer. Open the folder and double click “Virulence_Trade-off”. This should open Rstudio (if prompted, select Rstudio as the app to open this file type). Then open and run the files below in the specified order.\n\nR script “Data Cleaning.R” in the “2 Data Cleaning Script” folder uses “Data.Rda” and produces two clean data sets used for all further analyses. The data sets are all saved in the “3 Clean Data” folder and include:\n\n“SympAct_Any_Pos.Rda” Contains data for all influenza patients regardless of diagnosis method.\n“SympAct_Lab_Pos.Rda” Contains data for influenza patients diagnosed based on a PCR or rapid antigen test.\n\n\nIt is important to note that “SympAct_Lab_Pos.Rda” is a subset of “SympAct_Any_Pos.Rda” based on the method of diagnosis.\n\nFour R scripts in the “4 Analysis Scripts” folder (“Flu Symptoms Activity Univariate Model.R”, “Flu Symptoms Activity Univariate Plots.R”, and “Flu Symptoms Activity Univariate Tables.R”, “Multivariate Subset Selection.R”). The order you run these scripts does not matter. Results of each script are automatically saved in the “5 Results” folder.\nR Markdown “Manuscript.Rmd” is in the “6 Manuscript” folder. This combines all the relevant results and creates the main text as a Word document (some reformatting is required).\nR Markdown “Supplemental Material.Rmd” in the “7 Supplemental Material” folder generates the supplementary material as Word document."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#histogram-of-reported-activity-levels",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#histogram-of-reported-activity-levels",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Histogram of reported activity levels",
    "text": "Histogram of reported activity levels\nReported activity levels ranging from 0 to 10 with a median of 4 for those patients with a lab diagnosis of influenza (SM Figure @ref(fig:ActivityLabBarChart))\n\n\n\n\n\nHistogram of reported activity levels for patients with a lab diagnosis of influenza."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#table-of-symptoms",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#table-of-symptoms",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Table of symptoms",
    "text": "Table of symptoms\nSM Table @ref(tab:SympLabTable) shows the symptoms among patients with a lab-based diagnosis.\n\n\n\nSymptoms of the 324 patients with laboratory based flu diagnosis. The table shows the number of patients who reported having the following symptoms and the corresponding percentage.\n\n\n\nOverall\n\n\n\n\nn\n324\n\n\nAbdominal Pain = Yes (%)\n38 (11.7)\n\n\nBreathlessness = Yes (%)\n128 (39.5)\n\n\nChest Congestion = Yes (%)\n194 (59.9)\n\n\nChest Pain = Yes (%)\n110 (34.0)\n\n\nChills/Sweats = Yes (%)\n287 (88.6)\n\n\nCough = Yes (%)\n306 (94.4)\n\n\nDiarrhea = Yes (%)\n40 (12.3)\n\n\nEar Pain = Yes (%)\n59 (18.2)\n\n\nEye Pain = Yes (%)\n48 (14.8)\n\n\nFatigue = Yes (%)\n304 (93.8)\n\n\nHeadache = Yes (%)\n273 (84.3)\n\n\nItchy Eyes = Yes (%)\n75 (23.1)\n\n\nMyalgia = Yes (%)\n290 (89.5)\n\n\nNasal Congestion = Yes (%)\n255 (78.7)\n\n\nNausea = Yes (%)\n119 (36.7)\n\n\nRunny Nose = Yes (%)\n234 (72.2)\n\n\nSleeplessness = Yes (%)\n183 (56.5)\n\n\nSneeze = Yes (%)\n177 (54.6)\n\n\nSore Throat = Yes (%)\n265 (81.8)\n\n\nSubjective Fever = Yes (%)\n242 (74.7)\n\n\nSwollen Lymph Nodes = Yes (%)\n127 (39.2)\n\n\nTooth Pain = Yes (%)\n60 (18.5)\n\n\nVomiting = Yes (%)\n43 (13.3)\n\n\nWeakness = Yes (%)\n306 (94.4)\n\n\nWheezing = Yes (%)\n105 (32.4)"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#univariate-and-subset-selection",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#univariate-and-subset-selection",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Univariate and subset selection",
    "text": "Univariate and subset selection\nCorrelations between activity level and each symptom from the univariate linear analysis and the multivariate regression model selected using cross-validation (SM Table @ref(tab:LmActvSympLab)).\n\nResults of the univariate and multivariate linear regression of symptoms and activity. The coefficients are the estimated effect on activity when the symptom is present. The multivariate model was selected with a sequential forward floating selection, minimizing the RMSE on test data through a 5-fold cross validation (20 times repeated). 95%CI = The 95% confidence interval for the coefficient.\n\n\n\n\n\n\n\n\n\nDependent: Activity Level\n\nMean (sd)\nCoefficient (univariable)\nCoefficient (multivariable)\n\n\n\n\nAbdominal Pain\nNo\n4.4 (2.6)\n-\n-\n\n\n\nYes\n3.4 (2.7)\n-1.01 (-1.90 to -0.12, p=0.026)\n-\n\n\nBreathlessness\nNo\n4.3 (2.7)\n-\n-\n\n\n\nYes\n4.1 (2.5)\n-0.21 (-0.81 to 0.38, p=0.477)\n-\n\n\nChest Congestion\nNo\n4.7 (2.9)\n-\n-\n\n\n\nYes\n4.0 (2.4)\n-0.65 (-1.24 to -0.07, p=0.029)\n-\n\n\nChest Pain\nNo\n4.4 (2.7)\n-\n-\n\n\n\nYes\n4.0 (2.6)\n-0.38 (-0.99 to 0.23, p=0.217)\n-\n\n\nChills/Sweats\nNo\n5.8 (2.8)\n-\n-\n\n\n\nYes\n4.1 (2.6)\n-1.75 (-2.64 to -0.86, p&lt;0.001)\n-0.90 (-1.79 to -0.02, p=0.046)\n\n\nCough\nNo\n4.2 (3.2)\n-\n-\n\n\n\nYes\n4.3 (2.6)\n0.10 (-1.16 to 1.36, p=0.875)\n-\n\n\nDiarrhea\nNo\n4.4 (2.6)\n-\n-\n\n\n\nYes\n3.6 (2.6)\n-0.73 (-1.60 to 0.15, p=0.103)\n-\n\n\nEar Pain\nNo\n4.4 (2.6)\n-\n-\n\n\n\nYes\n3.7 (2.7)\n-0.69 (-1.44 to 0.05, p=0.068)\n-\n\n\nEye Pain\nNo\n4.2 (2.6)\n-\n-\n\n\n\nYes\n4.4 (2.9)\n0.21 (-0.61 to 1.02, p=0.619)\n-\n\n\nFatigue\nNo\n5.7 (2.5)\n-\n-\n\n\n\nYes\n4.2 (2.6)\n-1.53 (-2.72 to -0.34, p=0.012)\n-\n\n\nHeadache\nNo\n5.6 (2.8)\n-\n-\n\n\n\nYes\n4.0 (2.6)\n-1.57 (-2.35 to -0.80, p&lt;0.001)\n-1.23 (-1.97 to -0.49, p=0.001)\n\n\nSleeplessness\nNo\n4.9 (2.7)\n-\n-\n\n\n\nYes\n3.8 (2.5)\n-1.14 (-1.71 to -0.57, p&lt;0.001)\n-0.91 (-1.44 to -0.37, p=0.001)\n\n\nItchy Eyes\nNo\n4.4 (2.7)\n-\n-\n\n\n\nYes\n3.7 (2.5)\n-0.72 (-1.40 to -0.04, p=0.038)\n-\n\n\nMyalgia\nNo\n5.4 (2.9)\n-\n-\n\n\n\nYes\n4.1 (2.6)\n-1.32 (-2.25 to -0.38, p=0.006)\n-\n\n\nNasal Congestion\nNo\n4.4 (2.7)\n-\n-\n\n\n\nYes\n4.2 (2.6)\n-0.22 (-0.93 to 0.49, p=0.542)\n-\n\n\nNausea\nNo\n4.7 (2.7)\n-\n-\n\n\n\nYes\n3.6 (2.4)\n-1.08 (-1.67 to -0.49, p&lt;0.001)\n-\n\n\nSore Throat\nNo\n4.4 (2.6)\n-\n-\n\n\n\nYes\n4.2 (2.7)\n-0.20 (-0.95 to 0.55, p=0.605)\n-\n\n\nRunny Nose\nNo\n4.6 (2.6)\n-\n-\n\n\n\nYes\n4.1 (2.7)\n-0.50 (-1.14 to 0.15, p=0.129)\n-\n\n\nSneeze\nNo\n4.6 (2.7)\n-\n-\n\n\n\nYes\n4.0 (2.6)\n-0.67 (-1.24 to -0.09, p=0.024)\n-\n\n\nSubjective Fever\nNo\n5.2 (2.5)\n-\n-\n\n\n\nYes\n3.9 (2.6)\n-1.25 (-1.90 to -0.60, p&lt;0.001)\n-0.67 (-1.32 to -0.01, p=0.047)\n\n\nSwollen Lymph Nodes\nNo\n4.4 (2.7)\n-\n-\n\n\n\nYes\n4.0 (2.5)\n-0.46 (-1.05 to 0.13, p=0.128)\n-\n\n\nTooth Pain\nNo\n4.3 (2.6)\n-\n-\n\n\n\nYes\n4.1 (2.7)\n-0.24 (-0.98 to 0.50, p=0.526)\n-\n\n\nVomiting\nNo\n4.5 (2.6)\n-\n-\n\n\n\nYes\n2.8 (2.2)\n-1.64 (-2.48 to -0.81, p&lt;0.001)\n-1.39 (-2.18 to -0.60, p=0.001)\n\n\nWeakness\nNo\n6.6 (2.4)\n-\n-\n\n\n\nYes\n4.1 (2.6)\n-2.49 (-3.72 to -1.25, p&lt;0.001)\n-1.50 (-2.69 to -0.31, p=0.014)\n\n\nWheezing\nNo\n4.4 (2.7)\n-\n-\n\n\n\nYes\n4.0 (2.5)\n-0.46 (-1.07 to 0.16, p=0.144)\n-"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#distribution-of-scores",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#distribution-of-scores",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Distribution of scores",
    "text": "Distribution of scores\nThe infectiousness score is skewed left with more than half of the patients having a score of 4 or 5 (SM Figure @ref(fig:IandMLabBarChart)A). The morbidity score is more centered with no patient having a score of 0,1,19 or 20 (SM Figure @ref(fig:IandMLabBarChart)B).\n\n\n\n\n\n(A) Histogram of infectiousness score for patients with a lab diagnosis of influenza. (B) Histogram of morbidity score for patients with a lab diagnosis of influenza."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#correlation-between-number-and-severity-of-symptoms",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#correlation-between-number-and-severity-of-symptoms",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Correlation between number and severity of symptoms",
    "text": "Correlation between number and severity of symptoms\nThe data we have available reports most of the symptoms as absence or presence. If more symptoms correlate positively with stronger symptoms, using absence/presence data only is a valid, albeit less powerful approach. More problematically is a situation in which the number and strength of symptoms correlate negatively. For example, a person having fewer symptoms might “make up” for the lower number of symptoms by having a more severe form. Such a relation would invalidate our approach of adding presence/absence symptoms to arrive at a given score. While we cannot thoroughly test potential correlations between the quantity and strength of symptoms on all our data, we do have severity information on the cough, weakness, and body aches symptoms. This allows us to evaluate the relation between the number of symptoms and the severity of those symptoms.\nWe find that as the number of infectiousness-related symptoms (i.e., our infectiousness scores) increases, there is an increase in cough intensity (SM Figure @ref(fig:Infect1CoughFig)). The same relationship is found between the number of morbidity-related symptoms (i.e., our morbidity scores) and the severity of weakness and body aches (SM Figures @ref(fig:Morbidity1WeaknessFig) and @ref(fig:Morbidity1BodyAchesFig)). While not conclusive, this evidence suggests that our assumption that symptom absence/presence also captures symptom severity seems to be defensible.\n\n\n\n\n\nRelationship between cough intensity and the infectiousness score from main text using all Y/N variables plausibly related to infectiousness.\n\n\n\n\n\n\n\n\n\nRelationship between weakness intensity and the morbidity score from main text using all Y/N variables related to morbidity.\n\n\n\n\n\n\n\n\n\nRelationship between body ache intensity and the morbidity score from main text using all Y/N variables related to morbidity."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#alternative-approaches-to-calculate-the-infectiousness-score",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#alternative-approaches-to-calculate-the-infectiousness-score",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Alternative approaches to calculate the infectiousness score",
    "text": "Alternative approaches to calculate the infectiousness score\nIn the main text, we use all of the available yes/no symptoms that can feasibly be related to infectiousness. Since there is no consensus about which symptoms or routes of transmission are the most important, we also consider how robust the results are using several different versions of infectiousness scores.\nWhile chest congestion might be a proxy for pathogen load, i.e., more congestion could indicate higher levels of a pathogen, in which case it could impact infectiousness. However, it is true that chest congestion alone without coughing or sneezing might not lead to increased infectiousness (though some recent studies suggest that breathing alone accounts for a large fraction of expelled influenza virions [1]). To explore if inclusion or exclusion of chest congestion in the infectiousness scores made a difference, we created a score excluding it to see if the overall conclusions would change. The new score values ranged from 0 to 4 (SM Figure @ref(fig:InfectScore2Fig)A).\nThe same overall relationship is observed between the new infectiousness score and activity. There is still a curve. Spearman’s rank correlation indicates a negative relationship with (\\(r=\\) -0.11 (95% CI: -0.22, -0.00)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 3.772, \\(df =\\) 1, \\(p\\) 0.05) (SM Figure @ref(fig:InfectScore2Fig)B).\nWhen compared to the morbidity score, the same overall trends from the primary analysis were observed. Spearman’s rank correlation (\\(r=\\) 0.17 (95% CI: 0.06, 0.27)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 11.323, \\(df =\\) 1, \\(p\\) &lt; 0.01). We find a mean 1.5 fold increase in the new infectiousness score going from the lowest to the highest morbidity score (SM Figure @ref(fig:InfectScore2Fig)C).\n\n\n\n\n\nInfectiousness score without chest congestion\n\n\n\n\nHow patients define congestion symptoms is very subjective [2], so we created a score excluding both of the congestion-related variables to see if the overall conclusions would change. The new score could have a value of 0 to 3 (SM Figure @ref(fig:InfectScore3Fig)A).\nThe same overall relationship is observed between the new infectiousness score and activity. The curved relationship is not as clear but still present. Spearman’s rank correlation indicates negative relationship with (\\(r=\\) -0.11 (95% CI: -0.22, -0.00)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 4.599, \\(df =\\) 1, \\(p\\) 0.03) (SM Figure @ref(fig:InfectScore3Fig)B).\nWhen compared to the morbidity score again, the same trends were observed, and Spearman’s rank correlation indicates positive relationship (\\(r=\\) 0.16 (95% CI: 0.05, 0.26)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 10.023, \\(df =\\) 1, \\(p\\) &lt; 0.01). We find a mean 1.5 fold increase in the new infectiousness score going from the lowest to the highest morbidity score (SM Figure @ref(fig:InfectScore3Fig)C).\n\n\n\n\n\nInfectiousness score without chest and nasal congestion variables\n\n\n\n\nFor the score used in the main text, we included all relevant symptoms even if they can be considered strongly related. This might lead to potential double-counting of some symptoms. To evaluate if this might cause problems, we created an alternative score that removed highly correlated variables based on two cut off values of Yule’s Q [3]. There is no commonly used value to define a cut-off at which correlated variables should be removed. We decided to use an absolute correlation of 0.9 or 0.75 for our cut off. When using the 0.9 cut off only very strongly correlated variables were removed, while for the 0.75 even intermediately strong correlations lead to the removal of one of the variables [4]. For any pair of symptoms with a positive or negative correlation of 0.9 or greater, the more informative symptom (having the proportion Yes/No closest to 50%) was kept[5]. For our data, cough and chest congestion had a Yule’s Q of 0.933, and chest congestion had the best balance between yes and no responses, so it was kept. When relaxing the correlation to 0.75, there is no change in the variables included in the score.\nThe score values range from 0 to 4 (SM Figure @ref(fig:InfectScore4Fig)A). The same overall relationship is observed between the new infectiousness score and activity. The curve is present, Spearman’s rank correlation indicates negative relationship with (\\(r=\\) -0.16 (95% CI: -0.26, -0.05)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 7.138, \\(df =\\) 1, \\(p\\) &lt; 0.01) (SM Figure @ref(fig:InfectScore4Fig)B).\nWhen compared to the morbidity score again the same overall trends were observed with Spearman’s rank correlation indicates positive relationship (\\(r=\\) 0.28 (95% CI: 0.18, 0.38)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 25.818, \\(df =\\) 1, \\(p\\) &lt; 0.01). We find a mean 2.1 fold increase in the new infectiousness score going from the lowest to the highest morbidity score (SM Figure @ref(fig:InfectScore4Fig)C).\n\n\n\n\n\nInfectiousness score removing variables determined to be redundant based on Yule’s Q"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#alternative-approaches-to-calculate-morbidity-score",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#alternative-approaches-to-calculate-morbidity-score",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Alternative approaches to calculate morbidity score",
    "text": "Alternative approaches to calculate morbidity score\nTo see the impact of removing correlated variables from the morbidity score, we used the same methods applied to the infectiousness score above. Among the morbidity symptoms, only vomiting and weakness correlated greater than 0.9. Vomiting was included in the score since it was more balanced then weakness, which was present in 94% of patients. This score using 0.9 cut off had a possible range of 0 to 19. There are no patients with a morbidity score of 0,1,18,19 (SM Figure @ref(fig:ImpactScore2Fig)A). The same relationships observed in the main text are seen when the morbidity score is compared to activity and infectiousness scores.\nThere is a negative correlation between the morbidity score, and the patient’s self-reported activity level suggests that higher morbidity score is associated with reduced activity levels. Spearman’s rank correlation indicates negative relationship (\\(r=\\) -0.31 (95% CI: -0.41, -0.21)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 36.004, \\(df =\\) 1, \\(p\\) &lt; 0.01). We find a mean 4.3 fold decrease in activity level going from the lowest to the highest morbidity score (SM Figure @ref(fig:ImpactScore2Fig)B).\nThere is a positive correlation between the morbidity and infectiousness scores show a positive correlation. Spearman’s rank correlation indicates positive relationship (\\(r=\\) 0.28 (95% CI: 0.18, 0.38)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 25.942, \\(df =\\) 1, \\(p\\) &lt; 0.01). We find a mean 1.7 fold in the infectiousness score going from the lowest to the highest morbidity score (SM Figure @ref(fig:ImpactScore2Fig)C).\n\n\n\n\n\nMorbidity score removing variables determined to be redundant using the absolute value of Yule’s Q of 0.9 or more\n\n\n\n\nThe score created using the 0.75 cut off was different, with a total of 6 symptoms being excluded. Starting with the highest correlations first: Weakness/Vomit (Q=1) keep vomit, Tooth pain/Headache (Q=.86) keep Tooth pain, Chills Sweats/SoreThroat (Q=-.8) keep Chills Sweats, Fatigue/BodyAches (Q=.80) keep BodyAches, Vomit/Nausea (Q=.79) keep Nausea, SubjectiveFever/ChillsSweats (Q=.76) keep SubjectiveFever. The 0.75 cut off morbidity score included Subjective Fever, Myalgia, Sleeplessness, Breathlessness, Wheezing, Chest pain, Abdominal Pain, Diarrhea, Nausea, Ear Pain, Tooth pain, Eye pain, Itchy Eyes, and Swollen Lymph Nodes. This morbidity score has a possible value of 0 to 14. Compared to the morbidity score used in the main text and 0.9 cut off there are now 12 patients with a score of 0 or 1, but there are still no patients with a score of 13 or 14. (SM Figure @ref(fig:ImpactScore3Fig)A). Again the overall results remain the same despite using a different version of the score.\nThere is a negative correlation between the morbidity score and the patient’s self-reported activity level. Spearman’s rank correlation indicates negative relationship (\\(r=\\) -0.26 (95% CI: -0.36, -0.16)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 24.987, \\(df =\\) 1, \\(p\\) &lt; 0.01). We find a mean 2.9 fold reduction in activity level going from the lowest to the highest morbidity score (SM Figure @ref(fig:ImpactScore3Fig)B).\nThe relationship between the morbidity and infectiousness scores show a positive correlation. Spearman’s rank correlation indicates positive relationship (\\(r=\\) 0.29 (95% CI: 0.18, 0.38)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 25.942, \\(df =\\) 1, \\(p\\) &lt; 0.01). We find a mean 1.7 fold increase in the infectiousness score going from the lowest to the highest morbidity score (SM Figure @ref(fig:ImpactScore3Fig)C).\n\n\n\n\n\nMorbidity score removing variables determined to be redundant using the absolute value of Yule’s Q of 0.75 or more"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#description-of-the-population",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#description-of-the-population",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Description of the population",
    "text": "Description of the population\nInfluenza diagnosis for our population is determined using three different methods a rapid antigen test, a PCR test, or an empirical diagnosis by a physician. In the main text, we considered any person who was diagnosed by either a rapid antigen or PCR test as having influenza. Here we repeat the analyses completed in the main text with the addition of patients with a diagnosis of influenza empirically based on symptoms. Patients with an empirical diagnosis are generally defined as having influenza-like illness (ILI). In total, there are 735 patients with any diagnosis of influenza. Among these patients, the activity levels ranged from 0 to 10, with a median of 4. All of the patients had symptoms of disease. The most common symptom is weakness, and the least common symptom is vomiting (SM Table @ref(tab:SympAnyTable)).\n\n\n\nOut of the 735 patients included the table shows the number of patients who reported having the following symptoms and the corresponding percentage.\n\n\n\nOverall\n\n\n\n\nn\n735\n\n\nAbdominal Pain = Yes (%)\n93 (12.7)\n\n\nBreathlessness = Yes (%)\n297 (40.4)\n\n\nChest Congestion = Yes (%)\n409 (55.6)\n\n\nChest Pain = Yes (%)\n234 (31.8)\n\n\nChills/Sweats = Yes (%)\n604 (82.2)\n\n\nCough = Yes (%)\n660 (89.8)\n\n\nDiarrhea = Yes (%)\n99 (13.5)\n\n\nEar Pain = Yes (%)\n162 (22.0)\n\n\nEye Pain = Yes (%)\n113 (15.4)\n\n\nFatigue = Yes (%)\n671 (91.3)\n\n\nHeadache = Yes (%)\n620 (84.4)\n\n\nItchy Eyes = Yes (%)\n182 (24.8)\n\n\nMyalgia = Yes (%)\n656 (89.3)\n\n\nNasal Congestion = Yes (%)\n565 (76.9)\n\n\nNausea = Yes (%)\n258 (35.1)\n\n\nRunny Nose = Yes (%)\n524 (71.3)\n\n\nSleeplessness = Yes (%)\n419 (57.0)\n\n\nSneeze = Yes (%)\n395 (53.7)\n\n\nSore Throat = Yes (%)\n614 (83.5)\n\n\nSubjective Fever = Yes (%)\n505 (68.7)\n\n\nSwollen Lymph Nodes = Yes (%)\n314 (42.7)\n\n\nTooth Pain = Yes (%)\n166 (22.6)\n\n\nVomiting = Yes (%)\n79 (10.7)\n\n\nWeakness = Yes (%)\n686 (93.3)\n\n\nWheezing = Yes (%)\n221 (30.1)"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#univariate-and-subset-selection-1",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#univariate-and-subset-selection-1",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Univariate and subset selection",
    "text": "Univariate and subset selection\nWe explored the univariate correlations between activity level and each symptom. All of the symptoms that were statistically significantly related to activity showed a negative correlation with activity level (SM Table @ref(tab:LmActvSympAny)). Based on the cross-validated variable selection, we found that a model that included chills/sweats, subjective fever, headache, weakness, sleeplessness, and vomiting creates the most predictive model (SM Table @ref(tab:LmActvSympAny)).\n\nResults of the univariate and multivariate linear regression of symptoms and activity. The coefficients are the estimated effect on activity when the symptom is present. The multivariate model was selected with a sequential forward floating selection, minimizing the root mean square error on test data through a 5-fold cross validation (20 times repeated). 95%CI = The 95% confidence interval for the coefficient.\n\n\n\n\n\n\n\n\n\nDependent: Activity Level\n\nMean (sd)\nCoefficient (univariable)\nCoefficient (multivariable)\n\n\n\n\nAbdominal Pain\nNo\n4.6 (2.6)\n-\n-\n\n\n\nYes\n3.8 (2.7)\n-0.78 (-1.35 to -0.20, p=0.008)\n-\n\n\nBreathlessness\nNo\n4.6 (2.7)\n-\n-\n\n\n\nYes\n4.2 (2.6)\n-0.39 (-0.78 to 0.00, p=0.052)\n-\n\n\nChest Congestion\nNo\n4.7 (2.7)\n-\n-\n\n\n\nYes\n4.2 (2.5)\n-0.49 (-0.88 to -0.11, p=0.012)\n-\n\n\nChest Pain\nNo\n4.6 (2.6)\n-\n-\n\n\n\nYes\n4.2 (2.8)\n-0.42 (-0.83 to -0.01, p=0.044)\n-\n\n\nChills/Sweats\nNo\n6.2 (2.5)\n-\n-\n\n\n\nYes\n4.1 (2.5)\n-2.08 (-2.56 to -1.61, p&lt;0.001)\n-1.30 (-1.79 to -0.81, p&lt;0.001)\n\n\nCough\nNo\n4.9 (2.8)\n-\n-\n\n\n\nYes\n4.4 (2.6)\n-0.48 (-1.11 to 0.15, p=0.137)\n-\n\n\nDiarrhea\nNo\n4.6 (2.7)\n-\n-\n\n\n\nYes\n3.7 (2.5)\n-0.85 (-1.41 to -0.29, p=0.003)\n-\n\n\nEar Pain\nNo\n4.5 (2.6)\n-\n-\n\n\n\nYes\n4.2 (2.7)\n-0.34 (-0.80 to 0.12, p=0.149)\n-\n\n\nEye Pain\nNo\n4.5 (2.7)\n-\n-\n\n\n\nYes\n4.5 (2.6)\n0.05 (-0.48 to 0.58, p=0.855)\n-\n\n\nFatigue\nNo\n5.5 (2.6)\n-\n-\n\n\n\nYes\n4.4 (2.6)\n-1.15 (-1.83 to -0.48, p=0.001)\n-\n\n\nHeadache\nNo\n5.6 (2.6)\n-\n-\n\n\n\nYes\n4.3 (2.6)\n-1.34 (-1.86 to -0.82, p&lt;0.001)\n-0.91 (-1.39 to -0.43, p&lt;0.001)\n\n\nSleeplessness\nNo\n5.0 (2.7)\n-\n-\n\n\n\nYes\n4.0 (2.5)\n-0.96 (-1.35 to -0.58, p&lt;0.001)\n-0.72 (-1.07 to -0.37, p&lt;0.001)\n\n\nItchy Eyes\nNo\n4.5 (2.7)\n-\n-\n\n\n\nYes\n4.4 (2.5)\n-0.07 (-0.52 to 0.37, p=0.742)\n-\n\n\nMyalgia\nNo\n5.5 (2.7)\n-\n-\n\n\n\nYes\n4.3 (2.6)\n-1.14 (-1.75 to -0.53, p&lt;0.001)\n-\n\n\nNasal Congestion\nNo\n4.8 (2.6)\n-\n-\n\n\n\nYes\n4.4 (2.7)\n-0.39 (-0.84 to 0.07, p=0.096)\n-\n\n\nNausea\nNo\n4.8 (2.7)\n-\n-\n\n\n\nYes\n3.8 (2.5)\n-0.99 (-1.39 to -0.60, p&lt;0.001)\n-\n\n\nSore Throat\nNo\n4.5 (2.6)\n-\n-\n\n\n\nYes\n4.5 (2.6)\n-0.02 (-0.54 to 0.50, p=0.939)\n-\n\n\nRunny Nose\nNo\n4.6 (2.7)\n-\n-\n\n\n\nYes\n4.4 (2.6)\n-0.19 (-0.61 to 0.23, p=0.382)\n-\n\n\nSneeze\nNo\n4.6 (2.7)\n-\n-\n\n\n\nYes\n4.3 (2.6)\n-0.27 (-0.66 to 0.11, p=0.164)\n-\n\n\nSubjective Fever\nNo\n5.6 (2.5)\n-\n-\n\n\n\nYes\n4.0 (2.6)\n-1.62 (-2.01 to -1.22, p&lt;0.001)\n-0.92 (-1.33 to -0.51, p&lt;0.001)\n\n\nSwollen Lymph Nodes\nNo\n4.5 (2.6)\n-\n-\n\n\n\nYes\n4.4 (2.7)\n-0.13 (-0.52 to 0.25, p=0.495)\n-\n\n\nTooth Pain\nNo\n4.6 (2.6)\n-\n-\n\n\n\nYes\n4.2 (2.7)\n-0.40 (-0.86 to 0.05, p=0.084)\n-\n\n\nVomiting\nNo\n4.6 (2.6)\n-\n-\n\n\n\nYes\n3.1 (2.3)\n-1.57 (-2.18 to -0.96, p&lt;0.001)\n-1.27 (-1.84 to -0.71, p&lt;0.001)\n\n\nWeakness\nNo\n6.3 (2.5)\n-\n-\n\n\n\nYes\n4.3 (2.6)\n-1.98 (-2.73 to -1.22, p&lt;0.001)\n-0.92 (-1.64 to -0.21, p=0.011)\n\n\nWheezing\nNo\n4.7 (2.7)\n-\n-\n\n\n\nYes\n4.0 (2.5)\n-0.67 (-1.09 to -0.26, p=0.001)\n-"
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#computation-of-infectiousness-and-morbidity-scores",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#computation-of-infectiousness-and-morbidity-scores",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Computation of infectiousness and morbidity scores",
    "text": "Computation of infectiousness and morbidity scores\nWe used the same symptom classification presented in the main text. The median infectiousness score is 4, and a skewed distribution is present with most of the patients having a score of 4 or 5 (SM Figure @ref(fig:InfectScoreFig)).\n\n\n\n\n\nDistribution of the infectiousness score.\n\n\n\n\nThe median morbidity score is 9, and no patients have a morbidity score of 0, 1, 19, 20 (SM Figure @ref(fig:MorbScoreFig)). Such a centered distribution is assumed to be a result of patients felling ill enough to seek medical care, but none were sick enough to require urgent care or hospitalization.\n\n\n\n\n\nDistribution of the morbidity score."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#impact-of-infectiousness-score-on-activity",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#impact-of-infectiousness-score-on-activity",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Impact of infectiousness score on activity",
    "text": "Impact of infectiousness score on activity\nAnalysis of the impact of the infectiousness score on activity suggests that the value of this score has a negative correlation with the activity level. Spearman’s rank correlation is \\(r =\\) -0.10 (95% CI: -0.17, -0.03) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 7.083, \\(df =\\) 1, \\(p =\\) &lt; 0.01) (SM Figure @ref(fig:AnyTvAFig)). This is different from the main analysis were we did not observe a clear relationship between activity and the infectiousness score.\n\n\n\n\n\nActivity level for each level of the infectiousness score. The red diamond is the mean. The solid blue line is the linear regression fit. The shaded area is the 95% confidence interval for the linear regression."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#impact-of-morbidity-score-on-activity",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#impact-of-morbidity-score-on-activity",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Impact of morbidity score on activity",
    "text": "Impact of morbidity score on activity\nAnalysis of the impact of the morbidity score on activity suggests that the value of this score is correlated with the activity level of a patient, with higher morbidity correlating with reduced activity. Spearman’s rank correlation indicates a negative relationship \\(r =\\) -0.32 (95% CI: -0.38, -0.25) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 78.501, \\(df =\\) 1, \\(p\\) &lt; 0.01) (SM Figure @ref(fig:AnyMvAFig)). The observed pattern is clear, with a mean 3.6 fold decrease in activity level going from the lowest to the highest morbidity score.\n\n\n\n\n\nActivity level for each level of the morbidity score. The red diamond is the mean. The solid blue line is the linear regression fit. The shaded area is the 95% confidence interval for the linear regression."
  },
  {
    "objectID": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#impact-of-morbidity-score-on-infectiousness-score",
    "href": "starter-analysis-exercise/code/ProcSocB Supplemental Material/7 Supplemental Material/Supplemental Material.html#impact-of-morbidity-score-on-infectiousness-score",
    "title": "Supplemental Material: The Impact of Symptom and Activity Trade-offs on Transmission Potential of Patients Infected with Influenza",
    "section": "Impact of morbidity score on infectiousness score",
    "text": "Impact of morbidity score on infectiousness score\nAnalysis of the relationship between the morbidity and infectiousness scores show a positive correlation. Spearman’s rank correlation indicates a positive relationship ( \\(r =\\) 0.26 (95% CI: 0.19, 0.33)) and the Cochran-Mantel-Haenszel trend test is statistically significant (\\(\\chi^2 =\\) 44.505, \\(df =\\) 1, \\(p\\) &lt; 0.01) (SM Figure @ref(fig:AnyMvTFig)). Apart from the values activity levels for low morbidity score (with small sample sizes), the pattern is consistent with a mean 1.7 fold increase in the infectiousness score going from the lowest to the highest morbidity score.\n\n\n\n\n\nInfectiousness score for each level of the morbidity score. The red diamond is the mean. The solid blue line is the linear regression fit. The shaded area is the 95% confidence interval for the linear regression."
  }
]